{% extends "base.html" %}
{% block title %} HILUL {% endblock %}
{% block body %}
<p>
Coding has come a long way in my field in a short amount of time. As recently as 5
years ago, most analysis was done in SAS. R was for the most advanced of analysts. Later, 
R began growing rapidly as the prospect of job automation took hold. Now, more Python users 
are coming into the fold, and the great &quot;R vs. Python&quot; debate has begun. 
<a href="https://www.linkedin.com/posts/alex-freberg_python-is-better-than-r-activity-6752637240578600960-a36V/?trk=public_profile_like_view&amp;originalSubdomain=ke">Click-bait hot takes</a> 
abound on the web. This is to be expected. Data scientists tend to be pretty opinionated.
</p>
<p><img src="https://cs410032000ad584321.blob.core.windows.net/mydata/dsPrimaDonna.png" alt="" style="width: 50%; height:50%;"/></p>

<h2>A summary of the R vs. Python Debate</h2>
<p>
There is no shortage of posts about this topic, so I will keep it short. The Python folks argue that <a href="https://pypl.github.io/PYPL.html">Python is the most popular coding language</a>. The sheer size of the community means that it will always be able to do more. R is fussy and esoteric, they say. The R side points out that R packages, especially those used in modeling, are often maintained by the top experts in their respective fields (<a href="https://cran.r-project.org/web/packages/survival/index.html">survival analysis</a>, <a href="https://www.taylorfrancis.com/books/mono/10.1201/9781315370279/generalized-additive-models-simon-wood">Generalized Additive Models</a>, and <a href="https://cran.r-project.org/web/packages/EpiModel/index.html">Epidemiological Network models</a>, to name a few). Additionally, the <a href="https://www.jstatsoft.org/index">Journal of Statistical Software</a> is an academic publication that introduces and explains software implementations of new statistical methods, and R is the most common choice.
</p>

<h2>Why the Debate Misses the Point</a></h2>
<p>
The R vs. Python debate is largely counterproductive because it places the focus on the language instead of the analyst. The biggest risk to your data science career is not &quot;choosing the wrong language&quot;, it is stubbornly choosing to work with only one language. Some of the oldest programming languages, COBOL and FORTRAN, are <a href="https://www.nytimes.com/2022/07/06/technology/cobol-jobs.html">highly desired in the financial sector</a> precisely because they perform critical roles in the financial code base whilst being known by very few people. Speaking of FORTRAN, it is still used in both <a href="https://www.r-bloggers.com/2014/04/fortran-and-r-speed-things-up/">R</a> and <a href="https://fortranwiki.org/fortran/show/Python">Python</a>. When there is an optimal and proper solution to a problem, the code tends to live forever, no matter the language. And, of course, new languages will be developed, such as <a href="https://julialang.org/">Julia</a>. Stick to one language at your own peril.
</p>

<p>
I am reminded of a story from my own life. Early in the COVID-19 pandemic, my wife and I got really into cycling. After consistent improvement early on, I hit a plateau. I wanted to upgrade my mountain bike for a $3,000 road bike. The road bike was perfectly engineered for the task: 11 pounds lighter with thinner tires to reduce friction. But, I soon realized something: the same gains and more were achievable if I rode my current bike more and stopped having post-ride beers on the weekends. Better yet, I would be the one who is 11 pounds lighter, not my bike. 
Talk about portable! So it is with data science: people often get frustrated and switch to shiny new tools instead of truly investing in their professional development. The worst part is, it tends to happen right as they were scratching the surface of a new, core concept in computer science, such as apply functions or multithreaded processing.
</p>

<h2>Common Data Science Tasks in R and Python</h2>
<p>
I will let you in on a little secret: R and Python look pretty darn similar for many data 
science tasks. To show you just how similar they can be, this blog post will walk through how 
both R and Python:
</p>

<ol>
  <li>Install and load special modules and packages developed by the community</li>
  <li>Work with the filesystem and system commands</li>
  <li>Connect to SQL databases and extract data</li>
  <li>Basic data exploration: understand what kinds of data you have and how many records there are</li>
  <li>Subset data: keep only what you need and get rid of everything else</li>
</ol>

<p>
Future posts will cover other topics, such as data aggregation and/or data visualization. For some of the database tasks, I will connect to a SQL server instance I stood up on a personal cloud account. 
If you would like to stand up your own version, Microsoft has a tutorial <a href="https://learn.microsoft.com/en-us/sql/samples/adventureworks-install-configure?view=sql-server-ver16&amp;tabs=ssms#deploy-to-azure-sql-database">here</a>.
</p>

<h2>Modules and Packages: Install, Load, Use</h2>

<p>Really, there are four notable differences here:</p>

<ol>
  <li>Python calls them &quot;Modules&quot;, and R calls them &quot;Packages&quot;</li>
  <li>R packages are installed in an R session while Python modules are installed from the shell</li>
  <li>As long as an R package has been installed, it can be called using the pkg::function() syntax. 
    Python modules must always be loaded before use.</li>
  <li>Python modules rely heavily on classes, where R tends to use more functions.</li>
</ol>

<p>
Let&lsquo;s speak to the last point briefly. Classes are objects with pre-defined structures, attributes, and methods. For example, the Python pandas module has a DataFrame class that has the attribute head to call the first few rows. For a pandas DataFrame called myDf, this attribute could be accessed with myDf.head(). R tends to use functions instead. In R, head is a function that can can be used on almost any object, and can be called with head(myDf). I suspect this is due to differences in philosophy: Python is a multi-purpose language that prioritizes and enforces rules to keep code organized and readable. R was built for a more specific purpose, so it prioritizes flexibility in its functions so that an analyst has the same tools for dataframes, matrices, or whatever object they happen to be working with that day. By the way, this idea of one mechanism working on multiple types is called <a href="https://bookdown.dongzhuoer.com/hadley/adv-r/s4-dispatch.html">method dispatching</a>.
</p>

<h3>Python</h3>
<p>
In Python, pip is the base package installer, but other options (like <a href="https://www.anaconda.com/">Anaconda</a>) exist. In either case, the syntax in similar:
</p>
<pre><code class='language-shell'>$ pip install numpy
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: numpy in /home/jondowns/.local/lib/python3.10/site-packages (1.23.5)
Note: you may need to restart the kernel to use updated packages.
</code></pre>

<p>
After installing modules, it is now available in a Python session. Now, we can start coding in our preferred editor.
</p>

<pre><code class='language-python'># Modules need to be explicitly loaded
import sqlchemy as sa
import pandas as pd
import os
import re
import glob

# You can also import specific subsets of a package
from urllib import request
</code></pre>

<p>
Python modules tend to make more heavy use of classes. In short, a class is a pre-defined with a certain structure. For example, pandas Python modules tend to have lots of sub-modules and attributes. For example, urllib has many modules, but in data science the &quot;request&quot; module is the most commonly used. In such cases, you may want to only import the specific part of the module that you need for the task at hand.
</p>

<pre><code class='language-python'># Not using &quot;pd&quot; for pandas causes an error
try:
  DataFrame({&quot;mycol&quot;: range(0,9)}).head()
except:
  print(&quot;Well, that didn't work...\n\n&quot;)

print("This works, though!")
print(pd.DataFrame({&quot;mycol&quot;: range(0,9)}).head())

</code></pre>

<table>
  <thead>
    <tr>
      <th></th>
      <th>mycol</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
    </tr>
    <tr>
      <th>5</th>
      <td>5</td>
    </tr>
    <tr>
      <th>6</th>
      <td>6</td>
    </tr>
    <tr>
      <th>7</th>
      <td>7</td>
    </tr>
    <tr>
      <th>8</th>
      <td>8</td>
    </tr>
  </tbody>
</table>

<h3>R</h3>

<p>
As previously mentioned, R packages are installed within a session. You may be asked to select a &quot;mirror&quot; the first time you install a package. Just use the cloud mirror. Any packages that are installed can be loaded with the library command. Note that the quotes are no longer needed after a package has been installed.
</p>

<pre><code class='language-R'># Install packages in R using install.packages()
# install.packages(&quot;jsonlite&quot;)
# Load packages with the &quot;library&quot; command
library(jsonlite)
library(tidyverse)
library(odbc)
library(DBI)
</code></pre>

<p>
You might see conflicts when you do this-- more on that in a minute. The tidyverse is a bit of a special case: it is a set of packages designed to modernize base R, both for performance and to be more intuitive. So when you load the tidyverse package, you're actually loading a universe of packages (hence the name). After a package is loaded, any functions from that package can be called. R is structured a little differently than Python here. In the Python example above, we had to reference the package pandas (pd) to call the data.frame command. In R, loading the library is sufficient:
</p>

<pre><code class='language-R'># Use mutate from one of the packages in the tidyverse
print(
  mutate(data.frame(nums = 1:10), new = cumsum(nums)
)
</code></pre>

<thead>
  <tr><th scope=col>nums</th><th scope=col>new</th></tr>
  <tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>
</thead>
<tbody>
  <tr><td> 1</td><td> 1</td></tr>
  <tr><td> 2</td><td> 3</td></tr>
  <tr><td> 3</td><td> 6</td></tr>
  <tr><td> 4</td><td>10</td></tr>
  <tr><td> 5</td><td>15</td></tr>
  <tr><td> 6</td><td>21</td></tr>
  <tr><td> 7</td><td>28</td></tr>
  <tr><td> 8</td><td>36</td></tr>
  <tr><td> 9</td><td>45</td></tr>
  <tr><td>10</td><td>55</td></tr>
</tbody>
</table>

<p>
If you did want to be explicit, you could use the package::fuction() notation. It can be used when multiple libraries use the same function name. By default, R will choose the function that was loaded last when 2+ functions have the same name. Many times, the package author INTENDED to overwrite a base R function, so in practice function masking is not a big problem. Python handles the same problem by forcing you to always be explicit. I must admit, I like the Python philosophy more here.
</p>

<pre><code class='language-R'># As long as an R package is installed, you can access its functions
# like this
dplyr::mutate(data.frame(nums=1:5), new = cumsum(nums))
</code></pre>

<table>
  <caption>data.frame: 5 × 2</caption>
  <thead>
    <tr><th>nums</th><th>new</th></tr>
    <tr><th>&lt;int&gt;</th><th>&lt;int&gt;</th></tr>
  </thead>
  <tbody>
    <tr><td>1</td><td> 1</td></tr>
    <tr><td>2</td><td> 3</td></tr>
    <tr><td>3</td><td> 6</td></tr>
    <tr><td>4</td><td>10</td></tr>
    <tr><td>5</td><td>15</td></tr>
  </tbody>
</table>

<h2>Explore the filesystem and access system commands</h2>
<p>
An underrated skill in data science is folder searching and navigating the filesystem. For example, I frequently have lots of CSV files with identical formats for multiple days listed in the same folder. Luckily, both R and Python have simple tools for this.
</p>

<h3>Python</h3>

<pre><code class='language-python'>print(os.getcwd()) # Prints working directory path
print(os.listdir(&quot;.&quot;)) # List files in working directory
print(os.listdir(&quot;..&quot;)) # List files in parent directory

print(&quot;\nUse globa module to look for files that match certain pattern&quot;)
glob.glob(&quot;./*.ipynb&quot;)
</code></pre>

<pre><code class='language-python'>/home/jondowns/Documents/blog_markdowns/RUserPyGuide
[&#39;basics.py&#39;, &#39;basics.r&#39;, &#39;.ipynb_checkpoints&#39;, &#39;TextAndPy.ipynb&#39;, &#39;R.ipynb&#39;, &#39;dsPrimaDonna.png&#39;]
[&#39;.git&#39;, &#39;.gitignore&#39;, &#39;blog_markdowns.Rproj&#39;, &#39;gamesToWin&#39;, &#39;getPRISMData&#39;, &#39;isPalindrome&#39;, &#39;makeNbaDb&#39;, &#39;RUserPyGuide&#39;, &#39;addToWebsite.sql&#39;]

Use glob module to look for files that match a certain pattern
[&#39;./TextAndPy.ipynb&#39;, &#39;./R.ipynb&#39;]
</code></pre>

<p>
You may also use system commands (Windows, Linux, Mac, etc.). I often use environment variables to store, say, a folder I commonly access for my job:
</p>

<pre><code class='language-python'>os.getenv(&quot;HOME&quot;)
&#39;/home/jondowns&#39;
</code></pre>

<h3>R</h3>
<p>In R, the syntax is remarkably similar:</p>

<pre><code class='language-R'># Note that, if you do not assign an object, it is printed (not saved)
getwd()
list.files(&quot;.&quot;) # List files in working directory
list.files(&quot;..&quot;) # List files in parent of working directory

# Look for specific files
list.files(&quot;.&quot;, pattern = &quot;*.ipynb&quot;) # Use regex to search

# Access environment variables
Sys.getenv(&quot;HOME&quot;)
</code></pre>

<pre><code class='language-R'>&lsquo;/home/jondowns/Documents/blog_markdowns/RUserPyGuide&rsquo;
&lsquo;basics.py&lsquo;  &rsquo;basics.r&lsquo;  &rsquo;dsPrimaDonna.png&lsquo;  &rsquo;R.ipynb&lsquo;  &rsquo;RUserPyGuide.html&lsquo;  &rsquo;TextAndPy.ipynb&rsquo;
&lsquo;addToWebsite.sql&lsquo;  &rsquo;blog_markdowns.Rproj&lsquo;  &rsquo;gamesToWin&lsquo;  &rsquo;getPRISMData&lsquo;  &rsquo;isPalindrome&lsquo;  &rsquo;makeNbaDb&lsquo;  &rsquo;RUserPyGuide&rsquo;
&lsquo;R.ipynb&lsquo;  &rsquo;TextAndPy.ipynb&rsquo;
&lsquo;/home/jondowns&rsquo;
&lsquo;/home/jondowns/Documents/blog_markdowns/RUserPyGuide&rsquo;
</code></pre>

<h2>Work with Databases</h2>
<p>
Assuming Pandas is being used for your Python work, database connections are eerily similar between the two languages. An important note: below, I connect to the database by writing most of the connection string directly into the code. You should not do that! It exposes your server address, user name, and password to others who are reading your code. I've stripped out the most sensitive parts. Environment variables, forcing the user to enter credentials, and other practices are much safer ways to handle connection strings.
</p>

<h3>Python</h3>
<pre><code class='language-python'># Create connection string, connect to server
connection_string = "mssql+pyodbc://readAdvWorks:Plznohackme!123"
  "@[REDACTED]/adventureworks?"\
  "driver=ODBC+Driver+18+for+SQL+Server"
cnxn = sa.create_engine(connection_string)

# Use the SQL information schema to check out what data are available
pd.read_sql(    
  &quot;&quot;&quot;
  SELECT TOP 5 *
  FROM INFORMATION_SCHEMA.COLUMNS
  WHERE TABLE_NAME = 'Customer' """, cnxn)
  &quot;&quot;&quot;
</code></pre>

<table>
  <thead>
    <tr>
      <th></th>
      <th>TABLE_CATALOG</th>
      <th>TABLE_SCHEMA</th>
      <th>TABLE_NAME</th>
      <th>COLUMN_NAME</th>
      <th>ORDINAL_POSITION</th>
      <th>COLUMN_DEFAULT</th>
      <th>IS_NULLABLE</th>
      <th>DATA_TYPE</th>
      <th>CHARACTER_MAXIMUM_LENGTH</th>
      <th>CHARACTER_OCTET_LENGTH</th>
      <th>...</th>
      <th>DATETIME_PRECISION</th>
      <th>CHARACTER_SET_CATALOG</th>
      <th>CHARACTER_SET_SCHEMA</th>
      <th>CHARACTER_SET_NAME</th>
      <th>COLLATION_CATALOG</th>
      <th>COLLATION_SCHEMA</th>
      <th>COLLATION_NAME</th>
      <th>DOMAIN_CATALOG</th>
      <th>DOMAIN_SCHEMA</th>
      <th>DOMAIN_NAME</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>adventureworks</td>
      <td>SalesLT</td>
      <td>Customer</td>
      <td>CustomerID</td>
      <td>1</td>
      <td>None</td>
      <td>NO</td>
      <td>int</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>1</th>
      <td>adventureworks</td>
      <td>SalesLT</td>
      <td>Customer</td>
      <td>NameStyle</td>
      <td>2</td>
      <td>None</td>
      <td>NO</td>
      <td>bit</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
      <td>adventureworks</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>2</th>
      <td>adventureworks</td>
      <td>SalesLT</td>
      <td>Customer</td>
      <td>Title</td>
      <td>3</td>
      <td>None</td>
      <td>YES</td>
      <td>nvarchar</td>
      <td>8.0</td>
      <td>16.0</td>
      <td>...</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
      <td>UNICODE</td>
      <td>None</td>
      <td>None</td>
      <td>SQL_Latin1_General_CP1_CI_AS</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>3</th>
      <td>adventureworks</td>
      <td>SalesLT</td>
      <td>Customer</td>
      <td>FirstName</td>
      <td>4</td>
      <td>None</td>
      <td>NO</td>
      <td>nvarchar</td>
      <td>50.0</td>
      <td>100.0</td>
      <td>...</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
      <td>UNICODE</td>
      <td>None</td>
      <td>None</td>
      <td>SQL_Latin1_General_CP1_CI_AS</td>
      <td>adventureworks</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>4</th>
      <td>adventureworks</td>
      <td>SalesLT</td>
      <td>Customer</td>
      <td>MiddleName</td>
      <td>5</td>
      <td>None</td>
      <td>YES</td>
      <td>nvarchar</td>
      <td>50.0</td>
      <td>100.0</td>
      <td>...</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
      <td>UNICODE</td>
      <td>None</td>
      <td>None</td>
      <td>SQL_Latin1_General_CP1_CI_AS</td>
      <td>adventureworks</td>
      <td>None</td>
      <td>None</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 23 columns</p>

<pre><code class='language-python'># Use our connection to query two tables from the database
cust = pd.read_sql(
  &quot;&quot;&quot;
  SELECT a.CustomerID
  , a.AddressType
  , b.AddressLine1
  , b.AddressLine2
  , b.City
  , b.StateProvince
  , b.CountryRegion
  , b.PostalCode
  , b.ModifiedDate
  FROM SalesLt.CustomerAddress AS a
  LEFT JOIN SalesLT.Address AS b ON a.AddressID = b.AddressID
  &quot;&quot;&quot;, cnxn)
</code></pre>

<h3>R</h3>
<p>
Again, the solutions are quite similar. In fact, it could be even more similar by writing the connection string as a single string. I chose to use the built-in arguments because that's how I would typically approach the problem in R.
</p>
<pre><code class='language-R'>cnxn &lt;- DBI::dbConnect(
    drv = odbc::odbc(),
    Driver = &quot;{ODBC Driver 18 for SQL Server}&quot;,
    server = &quot;[REDACTED]&quot;,
    database = &quot;adventureworks&quot;,
    uid = &quot;readAdvWorks&quot;
    pwd = &quot;Plznohackme!123&quot;) # Reminder: do not do this

# In addition to the SQL information schema tables, DBI has some convenience functions
dbListFields(cnxn, "Customer")
&quot;CustomerID&quot;  &quot;Title&quot; &quot;Suffix&quot;  &quot;CompanyName&quot;  &quot;SalesPerson&quot;  &quot;EmailAddress&quot;  &quot;PasswordHash&quot;  &quot;PasswordSalt&quot;  &quot;rowguid&quot;  &quot;ModifiedDate&quot;
</code></pre>

<p>
And, of course, let's run the same two queries as before. The main differnece between Python and R here is that Python lists the connection as the SECOND argument, and R lists it as the first. Radical, I know.
</p>

<pre><code class="language-R"># Query database
cust &lt;- DBI::dbGetQuery(cnxn, &quot;SELECT * FROM SalesLt.Customer&quot;)
custAdd &lt;- DBI::dbGetQuery(
    cnxn,
    &quot;SELECT a.CustomerID
    , a.AddressType
    , b.AddressLine1
    , b.AddressLine2
    , b.City
    , b.StateProvince
    , b.CountryRegion
    , b.PostalCode
    , b.ModifiedDate
    FROM SalesLt.CustomerAddress AS a
    LEFT JOIN SalesLT.Address AS b ON a.AddressID = b.AddressID&quot;)
</code></pre>

<h2>Initial Data Exploration</h2>
<p>
Now that data have been pulled in, we may want to explore it some. Check the number of rows, number of columns, see whether a column is a string or number, etc. Let's go through some examples.
</p>

<h3>Python</h3>

<p>
DataFrames are two-dimensional objects: they have rows (indexes) and columns. Think spreadsheet. Below, you'll see printout of the columns in our dataframe and the list of indices for each row. The row indices are expressed as a range of values (range function). dtype can be used to check the type of a column. Note that anything that has strings/characters in them will be given the &quot;object&quot; type.
</p>
<pre><code class='language-python'># Print out row and column names
print(&quot;Number of rows and columns&quot;)
print(cust.shape)

print(&quot;Columns: &quot;)
print(cust.columns)

print(&quot;Indices:&quot;)
print(cust.index)

print(&quot;\nData type of Customer ID:&quot;)
print(cust[&quot;CustomerID&quot;].dtype)

print(&quot;\nData type of Last Name:&quot;)
print(cust["LastName"].dtype)

</code></pre>
<pre><code class='language-bash'>Number of rows and columns
(847, 15)
Columns: 
Index([&lsquo;CustomerID&rsquo;, &lsquo;NameStyle&rsquo;, &lsquo;Title&rsquo;, &lsquo;FirstName&rsquo;, &lsquo;MiddleName&rsquo;,
       &lsquo;LastName&rsquo;, &lsquo;Suffix&rsquo;, &lsquo;CompanyName&rsquo;, &lsquo;SalesPerson&rsquo;, &lsquo;EmailAddress&rsquo;,
       &lsquo;Phone&rsquo;, &lsquo;PasswordHash&rsquo;, &lsquo;PasswordSalt&rsquo;, &lsquo;rowguid&rsquo;, &lsquo;ModifiedDate&rsquo;],
      dtype=object)
Indices:
RangeIndex(start=0, stop=847, step=1)

Data type of Customer ID:
int64

Data type of Last Name:
object
</code></pre>

<p>
And, a frequency table can for a column can be produced using value_counts(). This is often useful for cateogrical variables (say, an 'Age Group' category with 5 levels).
</p>
<pre><code class='language-python'>cust[&quot;SalesPerson&quot;].value_counts()</code></pre>
<pre><code class='language-bash'>adventure-works\shu0        151
adventure-works\jillian0    148
adventure-works\josé1       142
adventure-works\garrett1     78
adventure-works\jae0         78
adventure-works\pamela0      74
adventure-works\david8       73
adventure-works\linda3       71
adventure-works\michael9     32
Name: SalesPerson, dtype: int64</code></pre>

<pre><code class='language-python'># Use dim, nrow, and ncol to get rows/columns, and both
dim(cust) # Rows x columns

# Print out row and column names
colnames(cust) # Most common
rownames(cust)[1:5] # Less common

print(&quot;Data type of Customer ID:&quot;)
class(cust$CustomerID)

print(&quot;Data type of Last Name:&quot;)
class(cust$LastName)</code></pre>

<pre><code class="language-bash">[1] 847  15
   &lsquo;CustomerID&rsquo;  &lsquo;NameStyle&rsquo;  &lsquo;Title&rsquo;  &lsquo;FirstName&rsquo;  &lsquo;MiddleName&rsquo;  &lsquo;LastName&rsquo;  &lsquo;Suffix&rsquo;  &lsquo;CompanyName&rsquo;  &lsquo;SalesPerson&rsquo;  &lsquo;EmailAddress&rsquo;  &lsquo;Phone&rsquo;  &lsquo;PasswordHash&rsquo;  &lsquo;PasswordSalt&rsquo;  &lsquo;rowguid&rsquo;  &lsquo;ModifiedDate&rsquo;
    &lsquo;1&rsquo;  &lsquo;2&rsquo;  &lsquo;3&rsquo;  &lsquo;4&rsquo;  &lsquo;5&rsquo;

[1] &quot;Data type of Customer ID:&quot;
&lsquo;integer&rsquo;
[1] &quot;Data type of Last Name:&quot;
'character' 
</code></pre>

<h2>Subsetting Data</h2>
<p>
Okay, so you've explored the data a bit and now you are ready to start cutting it down. And I encourage you to cut it down! A lean, mean script that only pulls the data it needs is both more understandable and will run faster. Note: ideally, most subsetting is done in the SQL query, not in the code. If the data are not needed, they shouldn't be pulled in the first place! We are being inefficient for the sake of demonstration.
</p>

<h3>Python</h3>
<p>
When subsetting columns, it is often useful to store the: order/column names in its own dictionary. Then, that dictionary can be referred to down the line as needed.
</p>

<pre><code class='language-python'># Pick the columns you want to keep/reorder columns
keepCols = [&quot;CustomerID&quot;, &quot;FirstName&quot;, &quot;LastName&quot;,
    &quot;CompanyName&quot;, 
    &quot;SalesPerson&quot;, &quot;Phone&quot;,
    &quot;EmailAddress&quot;]
cust2 = cust[keepCols]
</code></pre>

<p>Subsetting by row is also incredibly useful. There are two main options:</p>
<ol>
  <li>Subset by the actual row index (0-847 in our case). The iloc command is used.</li>
  <li>Subset by logic: write a statement that evaluates to True/False, and only the rows pass are kept.</li>
</ol>

<pre><code class='language-python'>print(&quot;Subset to first row only&quot;)
print(cust2.iloc[0])
print(&quot;\nGet first 5 rows matching condition&quot;)
cust2[cust2[&quot;LastName&quot;].str.startswith(&quot;D&quot;)].head()
</code></pre>
<pre><code class='language-bash'>Subset to first row only
CustomerID                                 1
FirstName                            Orlando
LastName                                 Gee
CompanyName                     A Bike Store
SalesPerson          adventure-works\pamela0
Phone                           245-555-0173
EmailAddress    orlando0@adventure-works.com
Name: 0, dtype: object

Get first 5 rows matching condition
</code></pre>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CustomerID</th>
      <th>FirstName</th>
      <th>LastName</th>
      <th>CompanyName</th>
      <th>SalesPerson</th>
      <th>Phone</th>
      <th>EmailAddress</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>43</th>
      <td>66</td>
      <td>Alexander</td>
      <td>Deborde</td>
      <td>Neighborhood Store</td>
      <td>adventure-works\garrett1</td>
      <td>394-555-0176</td>
      <td>alexander1@adventure-works.com</td>
    </tr>
    <tr>
      <th>47</th>
      <td>75</td>
      <td>Aidan</td>
      <td>Delaney</td>
      <td>Paint Supply</td>
      <td>adventure-works\jillian0</td>
      <td>358-555-0188</td>
      <td>aidan0@adventure-works.com</td>
    </tr>
    <tr>
      <th>50</th>
      <td>78</td>
      <td>Stefan</td>
      <td>Delmarco</td>
      <td>Preferred Bikes</td>
      <td>adventure-works\linda3</td>
      <td>819-555-0186</td>
      <td>stefan0@adventure-works.com</td>
    </tr>
    <tr>
      <th>54</th>
      <td>84</td>
      <td>Della</td>
      <td>Demott Jr</td>
      <td>Rewarding Activities Company</td>
      <td>adventure-works\garrett1</td>
      <td>752-555-0185</td>
      <td>della0@adventure-works.com</td>
    </tr>
    <tr>
      <th>58</th>
      <td>93</td>
      <td>Prashanth</td>
      <td>Desai</td>
      <td>Stationary Bikes and Stands</td>
      <td>adventure-works\jillian0</td>
      <td>138-555-0156</td>
      <td>prashanth0@adventure-works.com</td>
    </tr>
  </tbody>
</table>

<p>
Both columns and rows can be subset at once using the loc attribute of the dataframe. This works like matrix notation in R: the first argument is used to reference rows, and the second is used to reference columns. Below, I look for any rows where the last name starts with &quot;D&quot;, and I am pulling both the last name and the salesperson.
</p>

<pre><code class='language-python'># Subset by both rows and columns-- use pd.DataFrame.loc()
cust2.loc[cust2[&quot;LastName&quot;].str.startswith(&quot;D&quot;),
          [&quot;SalesPerson&quot;, &quot;LastName&quot;]].head()
</code></pre>


<table>
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SalesPerson</th>
      <th>LastName</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>43</th>
      <td>adventure-works\garrett1</td>
      <td>Deborde</td>
    </tr>
    <tr>
      <th>47</th>
      <td>adventure-works\jillian0</td>
      <td>Delaney</td>
    </tr>
    <tr>
      <th>50</th>
      <td>adventure-works\linda3</td>
      <td>Delmarco</td>
    </tr>
    <tr>
      <th>54</th>
      <td>adventure-works\garrett1</td>
      <td>Demott Jr</td>
    </tr>
    <tr>
      <th>58</th>
      <td>adventure-works\jillian0</td>
      <td>Desai</td>
    </tr>
  </tbody>
</table>

<h3>R</h3>
<p>
The main difference to note on these types of commands is that R dataframe support what I will call &quot;matrix notation&quot;: meaning, you can subset columns with the syntax myDf[rows, cols]. This would work quite similarly to Python's myDf.loc[rows, cols]. It is a very powerful way to quickly subset and reorganize once you understand the basic syntax.
</p>

<pre><code class='language-R'># Pick the columns you want to keep/reorder columns
keepCols &lt;- c(
    &quot;CustomerID&quot;, &quot;FirstName&quot;, &quot;LastName&quot;,
    &quot;CompanyName&quot;, &quot;SalesPerson&quot;, &quot;Phone&quot;,
    &quot;EmailAddress&quot;)
cust2 &lt;- cust[, keepCols]

print(&quot;Subset to first row only&quot;)
print(cust2[1,])


print(&quot;\nGet first 5 rows matching condition&quot;)
head(cust2[grepl(&quot;^D&quot;, cust2$&quot;LastName&quot;), ])
</code></pre>
<pre><code class='language-bash'>[1] &quot;Subset to first row only&quot;
# A tibble: 1 × 7
  CustomerID FirstName LastName CompanyName        SalesPerson     Phone Email…¹
       <dbl> <chr>     <chr>    <chr>              <chr>           <chr> <chr>  
1         66 Alexander Deborde  Neighborhood Store "adventure-wor… 394-… alexan…
# … with abbreviated variable name ¹​EmailAddress
[1] &quot;\nGet first 5 rows matching condition&quot;
</code></pre>

<table>
  <caption>A tibble: 5 × 7</caption>
  <thead>
    <tr><th>CustomerID</th><th>FirstName</th><th>LastName</th><th>CompanyName</th><th>SalesPerson</th><th>Phone</th><th>EmailAddress</th></tr>
    <tr><th>&lt;dbl&gt;</th><th>&lt;chr&gt;</th><th>&lt;chr&gt;</th><th>&lt;chr&gt;</th><th>&lt;chr&gt;</th><th>&lt;chr&gt;</th><th>&lt;chr&gt;</th></tr>
  </thead>
  <tbody>
    <tr><td>66</td><td>Alexander</td><td>Deborde  </td><td>Neighborhood Store          </td><td>adventure-works\garrett1</td><td>394-555-0176</td><td>alexander1@adventure-works.com</td></tr>
    <tr><td>75</td><td>Aidan    </td><td>Delaney  </td><td>Paint Supply                </td><td>adventure-works\jillian0</td><td>358-555-0188</td><td>aidan0@adventure-works.com    </td></tr>
    <tr><td>78</td><td>Stefan   </td><td>Delmarco </td><td>Preferred Bikes             </td><td>adventure-works\linda3  </td><td>819-555-0186</td><td>stefan0@adventure-works.com   </td></tr>
    <tr><td>84</td><td>Della    </td><td>Demott Jr</td><td>Rewarding Activities Company</td><td>adventure-works\garrett1</td><td>752-555-0185</td><td>della0@adventure-works.com    </td></tr>
    <tr><td>93</td><td>Prashanth</td><td>Desai    </td><td>Stationary Bikes and Stands </td><td>adventure-works\jillian0</td><td>138-555-0156</td><td>prashanth0@adventure-works.com</td></tr>
  </tbody>
</table>

<h2>Conclusion</h2>

<p>
R and Python are not so different after all when it comes to data science. My advice is to focus on developing the advanced skills in whatever language they are most comfortable with. After those advanced skills are in your repertoire, converting them to a new language is just a matter of learning the new syntax. Tune in later for more comparisons of R vs. Python, and just keep coding! hidkfl;ajsdfl;kjasdf;lkasdjfl;asdfdl;as
</p>
{% endblock %}
